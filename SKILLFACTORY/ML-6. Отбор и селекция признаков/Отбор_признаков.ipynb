{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"t_IvORKWGuCH"},"outputs":[],"source":["import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error"]},{"cell_type":"markdown","metadata":{"id":"FtTudvkQGzRk"},"source":["# Загрузка данных"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CiadW5D9G07U"},"outputs":[],"source":["%%capture\n","!wget https://www.dropbox.com/s/64ol9q9ssggz6f1/data_ford_price.xlsx"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gmll87tAG2rK"},"outputs":[],"source":["data = pd.read_excel('data_ford_price.xlsx') "]},{"cell_type":"markdown","metadata":{"id":"zKZZVz_6IA1m"},"source":["#  Отбор признаков: мотивация"]},{"cell_type":"markdown","metadata":{"id":"dt3vhRQ2G_uP"},"source":["## Предобработка данных"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"CJdK-t3MHDSp"},"outputs":[],"source":["data = data[['price','year', 'cylinders', 'odometer', 'lat', 'long', 'weather']]\n","data.dropna(inplace = True)\n","\n","y = data['price']\n","x = data.drop(columns='price')\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"cell_type":"markdown","metadata":{"id":"kqjEj0ABG4ZD"},"source":["## Обучение модели"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650361775695,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"K0aIWfwpHSHN","outputId":"9d5779ab-7fea-43e4-f7d6-62317dfcc079"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 4682.957\n"]}],"source":["model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_predicted = model.predict(X_test)\n"," \n","mae = mean_absolute_error(y_test, y_predicted)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{"id":"TznnlORnHisT"},"source":["## Удаление избыточного признака"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"2uKP_vEMHoBa"},"outputs":[],"source":["x.drop('lat', axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"A7f7kV-6HrrL"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1650361779668,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"pJQpOM9kHtSe","outputId":"709029e0-e13b-4f2b-92f7-9fa807a81b0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 4672.930\n"]}],"source":["model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_predicted = model.predict(X_test)\n"," \n","mae = mean_absolute_error(y_test, y_predicted)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{"id":"E54vkz2xIGWm"},"source":["#  Отбор признаков: классификация методов"]},{"cell_type":"markdown","metadata":{"id":"dUnTavGgIpj0"},"source":["## Метод рекурсивного исключения признаков"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### RFE\n","\n","Метод рекурсивного исключения признаков (RFE) предполагает выбор признаков путём рекурсивного рассмотрения всё меньших и меньших наборов фичей.\n","\n","Сначала RFE обучается на изначальной выборке, и происходит оценка важности каждого признака. Затем наименее важные фичи удаляются. Эта процедура рекурсивно повторяется на сокращённом наборе до тех пор, пока в конечном итоге не будет достигнуто желаемое количество признаков в выборке.\n","\n","Выделим три наиболее значимых признака:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"UYdiW0RWIZ5V"},"outputs":[],"source":["from sklearn.feature_selection import RFE"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"n3MW_xlPIJHd"},"outputs":[],"source":["y = data['price']\n","x = data.drop(columns='price')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"uU5SYUHvOlbt"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1650361787999,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"qxZGlxQYITTm","outputId":"cf3cfc7c-1bb2-4a2b-b8c4-26a5857e251a"},"outputs":[{"data":{"text/plain":["array(['year', 'cylinders', 'lat'], dtype=object)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["estimator = LinearRegression()\n","selector = RFE(estimator, n_features_to_select=3, step=1)\n","selector = selector.fit(X_train, y_train)\n"," \n","selector.get_feature_names_out()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Также узнаем, как RFE проранжировал все доступные признаки:"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1650361789809,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"VdZbOvqdIebk","outputId":"ac89f779-2388-4185-8647-b8addd1cbfac"},"outputs":[{"data":{"text/plain":["Index(['year', 'cylinders', 'odometer', 'lat', 'long', 'weather'], dtype='object')"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["X_train.columns"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1650361793169,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"QJ93ms5kIlS7","outputId":"ae52c597-f97e-4d2f-d679-fb7b9e29ed8a"},"outputs":[{"data":{"text/plain":["array([1, 1, 4, 1, 3, 2])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["selector.ranking_"]},{"cell_type":"markdown","metadata":{"id":"_KhZgXCkK3Ap"},"source":["##  МЕТОДЫ ВЫБОРА ПРИЗНАКОВ НА ОСНОВЕ ФИЛЬТРОВ"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["В качестве фильтров для выбора признаков используются уже знакомые нам статистики, такие как коэффициент корреляции Пирсона, ANOVA и т. д. При этом выбор статистических показателей сильно зависит от типов переменных в данных.\n","\n","Чем больше известно о типе данных, тем проще выбрать подходящую статистическую меру для метода отбора признаков на основе фильтра. Ниже приведена схема-помощник в выборе метода селекции признаков."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"mVHuMD0eK8or"},"outputs":[],"source":["from sklearn.feature_selection import SelectKBest, f_regression"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Библиотека sklearn обеспечивает реализацию большинства полезных статистических показателей, например:\n","\n","        коэффициента корреляции Пирсона: f_regression();\n","        дисперсионного анализа ANOVA: f_classif();\n","        хи-квадрата: chi2();\n","        взаимной информации: mutual_info_classif() и mutual_info_regression().\n","\n","Кроме того, библиотека SciPy обеспечивает реализацию многих других статистических данных, таких как тау Кендалла (kendalltau) и ранговая корреляция Спирмена (spearmanr).\n","\n","sklearn также предоставляет множество различных методов фильтрации после расчёта статистики для каждой входной переменной с целевой.\n","\n","Два наиболее популярных метода:\n","\n","        выбор k лучших переменных: SelectKBest;\n","        выбор переменных верхнего процентиля: SelectPercentile.\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1650361806172,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"dc2EPKG5K39w","outputId":"4bc13ef2-9c06-47c6-f892-566135ee3dcd"},"outputs":[{"data":{"text/plain":["array(['year', 'cylinders', 'odometer'], dtype=object)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["selector = SelectKBest(f_regression, k=3)\n","selector.fit(X_train, y_train)\n"," \n","selector.get_feature_names_out()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["На этот раз odometer оказался в топе."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Задание 9.5. Модуль ML-6 (HW-03)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Обучите модель линейной регрессии на найденных двумя способами трёх важных признаках и сравните полученные результаты. Загрузите полученный ноутбук (в формате IPYNB) в форму ниже."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Сначала выделим три столбца-признака, которые мы определили с помощью RFE и разделим датасет на тренировочный и тестовый."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["y = data['price']\n","x = data[['year', 'cylinders', 'lat']]\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Теперь построим модель линейной регрессии, основанной на выделенных признаках и отобразим метрику."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 5096.570\n"]}],"source":["model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_predicted = model.predict(X_test)\n"," \n","mae = mean_absolute_error(y_test, y_predicted)\n","print('MAE: %.3f' % mae)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Можно уже заметить, что метрика значительно ухудшилась по сравнению с моделью, которая основана на всех доступных признаках."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Теперь проведем аналогичные манипуляции для признаков, отобранных с помощью SelectKBest."]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["y = data['price']\n","x = data[['year', 'cylinders', 'odometer']]\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 4708.946\n"]}],"source":["model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_predicted = model.predict(X_test)\n"," \n","mae = mean_absolute_error(y_test, y_predicted)\n","print('MAE: %.3f' % mae)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Метрика улучшилась на 300 единиц. Таким образом метод фильтрации SelectKBest показал себя лучше в задаче. Однако, такой результат также не идеален. Модель, построенная на всех признаках, кроме 'lat', показывает лучшую метрику."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Отбор_признаков.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
