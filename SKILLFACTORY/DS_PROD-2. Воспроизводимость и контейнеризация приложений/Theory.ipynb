{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предыдущем модуле мы рассмотрели базовые принципы работы с моделями на этапе продакшена.\n",
    "\n",
    "МЫ НАУЧИЛИСЬ:\n",
    "\n",
    "Img сохранять обученные модели в виде бинарных файлов, а также файлов других форматов, которые поддерживаются языками программирования, отличными от Python;\n",
    "\n",
    "Img локально разворачивать собственный веб-сервис с помощью фреймворка Flask, встраивая в его работу свою модель машинного обучения;\n",
    "\n",
    "Img оптимизировать работу этого веб-сервиса, увеличивая его пропускную способность с помощью таких инструментов, как uWSGI и NGINX.\n",
    "\n",
    "Однако, как мы уже упомянули в конце прошлого модуля, осталась одна проблема: наш сервис (да и сама модель) работает только на нашем компьютере. Когда мы зальём исходный код на GitHub, а наш коллега Василий склонирует себе репозиторий и попробует запустить сервис на своём «боевом» сервере, нет гарантии, что приложение запустится.\n",
    "\n",
    "Что, если на сервере Василия нет необходимых зависимостей, таких как Scikit Learn, Flask и так далее? Установить библиотеки несложно, но какие именно их версии нужны Василию? А что, если у него уже стоят некоторые библиотеки, которые вы использовали, но в совершенно другой версии, которая не совместима с вашим приложением?\n",
    "\n",
    "Кроме того, для обеспечения работы сервиса в связке uWSGI + NGINX Василию придётся проделывать все те манипуляции, которые мы производили в прошлом модуле. Вы уже должны были убедиться, что процесс настройки взаимодействия uWSGI + NGINX + Flask не из лёгких, пусть его и можно обернуть в некоторую инструкцию.\n",
    "\n",
    "А что, если, ко всему прочему, на сервере Василия стоит другая операционная система, например Windows, которая не поддерживает работу с uWSGI?\n",
    "\n",
    "Так много вопросов… И у нас есть на них ответы. Проблема, к которой мы подошли, называется проблемой воспроизводимости. О ней, как правило, не задумываются новички, однако она часто проявляется на этапе продакшена. Например, мы хотим перенести проект с локальной машины, где вели разработку, на реальный сервер, но из-за разницы в настройках и конфигурациях этот процесс становится болезненным и требует затрат времени, которого всегда остаётся очень мало на этапе продакшена.\n",
    "\n",
    "В этом модуле мы разберём, как сделать свой код воспроизводимым и как изолировать свой сервис так, чтобы его можно было запустить на любой машине, а самое главное — как сделать это быстро и просто.\n",
    "\n",
    "ЦЕЛИ МОДУЛЯ:\n",
    "\n",
    "Img Узнать, что такое воспроизводимость и какими инструментами её можно обеспечить.\n",
    "\n",
    "Img Познакомиться с терминами «виртуализация» и «контейнеризация».\n",
    "\n",
    "Img Научиться создавать виртуальные окружения, изолировать среду разработки, устанавливать и фиксировать зависимости в виртуальных окружениях.\n",
    "\n",
    "Img Познакомиться с инструментом контейнеризации Docker.\n",
    "\n",
    "Img Научиться писать Dockerfile, создавать образы контейнеров, запускать их, а также делиться ими с помощью хостинга docker-образов Docker Hub.\n",
    "\n",
    "Img Создать docker-образ для нашего веб-сервиса и запустить его в контейнере.\n",
    "\n",
    "С КАКИМ ПРОЕКТОМ БУДЕМ РАБОТАТЬ?\n",
    "\n",
    "В предыдущем модуле мы написали маленький веб-сервис. В нём функционирует модель машинного обучения, которая выполняет предсказания для данных, поступающих через POST-запросы по эндпоинту '/predict'.\n",
    "\n",
    "Перед прохождением модуля давайте зафиксируем, как должна выглядеть директория нашего проекта:\n",
    "\n",
    "├─web\n",
    "   ├─models\n",
    "        └─model.pkl\n",
    "   └─client.py\n",
    "   └─server.py\n",
    "Проект будет располагаться в директории web, в которой находятся файлы:\n",
    "\n",
    "server.py — содержит интерфейс сервера, реализованный на Flask. В интерфейсе предусмотрено два эндпоинта:\n",
    "'/' — корневой, по обращению к которому пользователю возвращается тестовое сообщение;\n",
    "'/predict' — предназначенный для обработки POST-запросов. Запросы приходят в виде списка из четырёх чисел в формате json(). Результатом выполнения запроса является JSON-словарь с ключом 'prediction' и значением-предсказанием модели.\n",
    "Вы писали функцию для обработки этого запроса в прошлом модуле.\n",
    "client.py — скрипт для тестирования POST-запросов на сервер.\n",
    "models — папка с моделями, в которой находится файл model.pkl с моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Воспроизводимость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код, разрабатываемый дата-сайентистом, должен быть воспроизводимым в постоянно меняющихся в условиях:\n",
    "\n",
    "меняются данные, поступающие на вход;\n",
    "трансформируются пайплайны предобработки данных;\n",
    "постоянно изменяются гиперпараметры алгоритмов;\n",
    "иногда модифицируются или вовсе удаляются алгоритмы популярных библиотек.\n",
    "В идеале ожидается, что выполнение кода должно приводить к одинаковым результатам в различных условиях. Именно с этой целью в некоторых заданиях вы встречали требование зафиксировать параметр random seed — таким образом, вы уже неоднократно сталкивались с проблемой воспроизводимости на практике.\n",
    "\n",
    "Воспроизводимость результатов является одним из главных показателей качества модели. Именно поэтому обеспечение воспроизводимости — одна из важнейших проблем в современном ML-инжиниринге.\n",
    "\n",
    "Мы можем доверять результату, полученному с помощью модели, только когда доподлинно известно, на какой выборке и с каким пайплайном предобработки она была построена. Кроме того, ожидается, что результаты будут консистентными (согласованными с исходными данными), так как необходимо однозначно понимать, какое изменение привело к улучшению или ухудшению результатов.\n",
    "\n",
    "Наиболее остро вопрос воспроизводимости стоит в случае, когда над одной моделью работает большая DS-команда. Каждый участник команды должен воспроизвести весь пайплайн и получить тот же самый результат. При этом возможные изменения должны доставляться в общий код так же быстро, сохраняя все требования к воспроизводимости.\n",
    "\n",
    "На схеме приведён классический пайплайн работы над моделью:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ИНСТРУМЕНТЫ ОБЕСПЕЧЕНИЯ ВОСПРОИЗВОДИМОСТИ:\n",
    "\n",
    "Версионирование кода.\n",
    "Обычно весь пайплайн представлен в виде частей кода, для работы с которым используется знакомая нам распределённая система управления версиями Git в совокупности с хостингом GitHub.\n",
    "\n",
    "Версионирование артефактов.\n",
    "В процессе работы над проектом появляются различные артефакты: датасеты, модели, файлы конфигурации и прочее. Для их версионирования обычно используются такие инструменты, как DVC и Sonatype Nexus.\n",
    "\n",
    "Виртуализация и контейнеризация.\n",
    "Одним из важнейших аспектов воспроизводимости является настройка окружения.\n",
    "\n",
    "Виртуализация — это технология изоляции, сохранения состояния и воспроизведения окружения. Благодаря ей вы можете воссоздать на другом компьютере точную копию вашего окружения и тем самым обеспечить воспроизводимость.\n",
    "\n",
    "Однако иногда воссоздания окружения недостаточно и необходимо обеспечить не только воспроизводимость версий библиотек, но и воспроизводимость среды выполнения программы — операционной системы, на которой реализован проект. Для этого прибегают к инструментам контейнеризации, таким как Docker.\n",
    "\n",
    "Все перечисленные выше инструменты мы подробно обсудим далее.\n",
    "\n",
    "Управление экспериментами.\n",
    "Для каждого запуска обучения необходимо фиксировать настройки гиперпараметров и сохранять их. В этом помогают системы управления экспериментами, например MLflow.\n",
    "\n",
    "Над созданием универсального стандарта воспроизводимости работают многие крупные компании. Это означает, что у каждой компании пока что существуют собственные требования к обеспечению воспроизводимости. Когда вы начнёте работать в DS-команде, ваши коллеги будут требовать от вас их соблюдения. Обычно чем крупнее компания, тем более серьёзные требования к воспроизводимости необходимо соблюдать. Поскольку единого стандарта пока не существует, пути и используемые в разных компаниях инструменты могут кардинально отличаться.\n",
    "\n",
    "Рекомендуем вам всегда помнить о задаче воспроизводимости результатов модели. Это позволит вам постепенно привить себе тот уровень культуры кода, который будет удовлетворять самые требовательные компании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Виртуализация и изолированность. Virtualenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обсуждении воспроизводимости мы упоминали, что одним из важнейших её требований является настройка окружения. Разные версии библиотек в разных проектах могут конфликтовать друг с другом, и становится сложно поддерживать работоспособность всех сервисов. Поэтому необходимо обеспечить не только одинаковые операционные системы, но и установку всех нужных библиотек и их версий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти в 100 % случаев при работе над реальным проектом вам потребуется воссоздать точное окружение на сервере, чтобы обеспечить единообразие среды выполнения. Это включает в себя не только стандартные установленные зависимости и интерпретатор Python, но и специфические зависимости, которые могут работать по-разному на разных операционных системах или на разных их версиях.\n",
    "\n",
    "Несколько лет назад для этих задач использовали программные решения для удалённого управления конфигурациями. Они создавали большой конфигурационный файл, в котором описывались все настройки, зависимости и библиотеки, и на его основе настраивались все удалённые машины. Одним из таких инструментов является Ansible. Он позволяет через SSH-соединение «проталкивать» файлы конфигурации на множество машин и таким образом обеспечивать единообразие.\n",
    "\n",
    "Другие системы, например Chef, обычно поступают наоборот: узлы «тянут» (pull) конфигурацию с главной машины. Chef используется и сейчас, когда необходимо привести парк машин к одинаковой конфигурации.\n",
    "\n",
    "ПРОБЛЕМЫ\n",
    "\n",
    "Когда в системе много сервисов и при этом каждый сервис запускается на разных машинах, становится тяжело следить за полнотой и правильностью конфигурационных файлов.\n",
    "На локальном компьютере разработчика может быть не установлено (или наоборот установлено) ПО, напрямую влияющее на стабильность работы приложения.\n",
    "Намного проще создать для каждого проекта виртуальную среду, изолированную от основной системы. Тогда каждый из проектов будет иметь свои независимые настройки, в том числе разные библиотеки и их версии.\n",
    "\n",
    "Когда мы говорим про изолированность, мы имеем в виду, что приложение будет запускаться в своей отдельной среде и таким образом не зависеть от ОС и настроек системы, на которой мы его разворачиваем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIRTUALENV\n",
    "\n",
    "Одним из наиболее популярных инструментов для создания изолированных сред в Python является virtualenv. Он обеспечивает работоспособность сервисов вне зависимости от того, какие они имеют зависимости.\n",
    "Примечание. Сначала мы будем изучать основы работы с виртуальными окружениями на «игрушечных» примерах, а затем рассмотрим, как настроить виртуальное окружение для нашего веб-сервиса.\n",
    "\n",
    "Предварительно создайте в своей операционной системе папку с именем project_a. Эта папка будет имитировать папку проекта, и на её основе мы продемонстрируем работу виртуальных окружений. Перейдите в созданную папку в терминале (команда cd /путь/до/папки) или откройте её в вашей IDE.\n",
    "\n",
    "Чтобы установить virtualenv, необходимо воспользоваться стандартной командой:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ pip install virtualenv\n",
    "\n",
    "Примечание. Здесь и далее символ $ будет означать, что команды выполняются в терминале (для Windows — в командной строке). Вводить его не нужно — вводите только текст команды!\n",
    "\n",
    "Напомним, что в VS Code терминал (в Windows — командную строку) можно открыть с помощью кнопки в верхнем меню IDE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как принципы работы с инструментом незначительно, но отличаются для различных UNIX-систем (Linux и MacOS) и Windows, мы приведём инструкции по работе для каждой из ОС.\n",
    "\n",
    "Примечание. Чтобы показать, что команды в терминале выполняются в виртуальном окружении, мы будем перед символом $ писать в скобках имя виртуального окружения, в котором происходит работа. Например:\n",
    "\n",
    "(project_a_venv) $ pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы создать новую среду, необходимо набрать в терминале команду:\n",
    "\n",
    "$ python3 -m venv <название сервиса>\n",
    "Например, следующая команда создаёт виртуальное окружение с именем project_a_venv:\n",
    "\n",
    "$ python3 -m venv project_a_venv\n",
    "После этого в вашей текущей директории появится папка проекта с именем, которое вы указали в команде venv.\n",
    "\n",
    "В UNIX-системах эта директория будет выглядеть примерно следующим образом (имена файлов могут незначительно отличаться в зависимости от версии Python, которую вы используете):\n",
    "\n",
    "img\n",
    "В директории bin лежат файлы, которые взаимодействуют с виртуальной средой, а в lib и lib64 содержится копия версии Python и все зависимости (библиотеки и их версии).\n",
    "\n",
    "Чтобы активировать виртуальную среду и зайти в нёе в UNIX-системах, необходимо запустить в терминале команду:\n",
    "\n",
    "$ source project_a_venv/bin/activate\n",
    "Если команда выполнилась успешно, вы увидите, что перед приглашением в командной строке появилась дополнительная надпись, совпадающая с именем виртуального окружения.\n",
    "\n",
    "В результате выполнения команды мы увидим следующее:\n",
    "\n",
    "img\n",
    "Выделенная красным строка говорит нам, что мы находимся в изолированном окружении project_a_venv.\n",
    "\n",
    "Таким образом вы полностью изолируете окружение своего проекта и можете установить все необходимые для работы проекта версии пакетов — эти версии не будут отражены в глобальном окружении Python и будут зафиксированы только в активированном виртуальном окружении.\n",
    "\n",
    "Например, выполним команду для установки библиотеки scikit-learn:\n",
    "\n",
    "(project_a_venv) $ pip install scikit-learn\n",
    "После установки библиотеки вы увидите, что в папке lib/python3.Х/site-packages (X — ваша версия Python) появится папка scikit-learn, а также зависимости, необходимые для работы этой библиотеки (например, numpy, scipy и joblib) — они устанавливаются вместе с ней автоматически.\n",
    "\n",
    "Чтобы выйти из виртуального окружения в область глобального окружения, необходимо ввести в терминале команду:\n",
    "\n",
    "$ deactivate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIRTUALENV И VS CODE\n",
    "\n",
    "Если вы разрабатываете свои программы в IDE, например в VS Code, то перемещаться между виртуальными окружениями становится совсем просто.\n",
    "\n",
    "Давайте предварительно создадим в папке нашего проекта пустой py-файл, чтобы VS Code понял, что мы работаем с языком Python. Назовём этот файл app.py.\n",
    "\n",
    "Чтобы переключиться между окружениями в VS Code, необходимо перейти в раздел выбора интерпретатора Python (правый нижний угол):\n",
    "\n",
    "img\n",
    "По умолчанию используется глобальное окружение. Нам нужно переключиться на только что созданное виртуальное окружение:\n",
    "\n",
    "img\n",
    "После этого необходимо перезапустить терминал (если он был открыт).\n",
    "\n",
    "Результат будет тем же, что и после активации виртуального окружения через командную строку:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ИЗОЛЯЦИЯ ЗАВИСИМОСТЕЙ\n",
    "\n",
    "Теперь давайте на примере рассмотрим, как работать с виртуальными окружениями.\n",
    "\n",
    "Рядом с папкой project_a создайте ещё одну папку проекта и назовите её project_b. В этой папке также создайте пустой файл app.py.\n",
    "\n",
    "Откройте два терминала: в первом перейдите в папку project_a, а во втором — в project_b. Также можно открыть эти папки в двух окнах VS Code.\n",
    "\n",
    "В папке с проектом А создадим виртуальное окружение с именем project_a_venv, активируем его и установим scikit-learn (если вы не делали этого ранее):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Ключ -q предназначен для установки без вывода справочной информации — «тихая» установка (от англ. quiet — тихий).\n",
    "\n",
    "Затем создадим виртуальное окружение в папке project_b с именем project_b_venv, активируем его и установим пакет pandas.\n",
    "\n",
    "UNIXWINDOWS\n",
    "$ python3 -m venv project_venv\n",
    "$ source project_b_venv/bin/activate \n",
    "(project_b_venv)$ pip install -q pandas\n",
    "Давайте посмотрим, какие библиотеки доступны внутри каждого из окружений. Для этого воспользуемся командой pip freeze, которая выводит список установленных пакетов с указанием номера их версии. Выполните в каждом из окружений команду:\n",
    "\n",
    "(project_{}_venv)$ pip freeze\n",
    "Для проекта А мы увидим примерно следующую картину:\n",
    "\n",
    "img\n",
    "Для проекта B список будет выглядеть так:\n",
    "\n",
    "img\n",
    "Примечание. На скриншотах приведены результаты работы команд только в UNIX-системах, так как они совпадают с результатами в Windows.\n",
    "\n",
    "Что мы видим? Списки установленных пакетов отличаются: например, библиотеки scikit-learn нет в виртуальном окружении проекта B, а библиотеки pandas нет в виртуальном окружении проекта A. Списки пакетов для проектов А и B пересекаются только в одном — библиотеке numpy. Так происходит потому, что и scikit-learn, и pandas требуют для своей стандартной работы пакет numpy.\n",
    "\n",
    "Теперь давайте взглянём на список глобально установленных пакетов. Для этого откроем ещё один терминал и, не активируя никаких окружений, напишем в нём команду для вывода списка установленных пакетов:\n",
    "\n",
    "$ pip freeze\n",
    "img\n",
    "В глобальном окружении находится совершенно другой список зависимостей.\n",
    "\n",
    "Примечание. Пакеты в глобальном окружении на вашем компьютере могут отличаться от приведённых на скриншоте.\n",
    "\n",
    "Только что мы посмотрели на пример изоляции: мы создали отдельные виртуальные окружения для каждого из проектов, зависимости которых изолированы друг от друга. Из приведённого примера становится интуитивно понятно, что виртуальные окружения существуют независимо от глобального и установка пакета в одно из них не означает, что пакет будет установлен в какое-то другое окружение, и наоборот.\n",
    "\n",
    "Например, если мы установим в глобальное окружение библиотеку numpy версии 1.19.2,\n",
    "\n",
    "$ pip install numpy==1.19.2\n",
    "то для виртуальных окружений проектов А и B версия numpy не изменится. Это утверждение справедливо и в обратную сторону. Такой механизм позволяет нам работать с проектами А и B независимо друг от друга и даже независимо от глобального окружения, тем самым гибко управляя проектами.\n",
    "\n",
    "Примечание. Очевидно, что попытка запустить в окружении код, использующий библиотеку, которая в нём не установлена, приведёт к ошибке. Например, если попробовать импортировать библиотеку pandas в файле app.py проекта A,\n",
    "\n",
    "Файл project_a/app.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
    "print(df)\n",
    "а после запустить этот файл из-под соответствующего виртуального окружения, мы получим ошибку импорта:\n",
    "\n",
    "(project_a_venv) $ python3 app.py\n",
    "\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/andrey/prod-2/project_a/app.py\", line 1, in <module>\n",
    "    import pandas as pd\n",
    "ModuleNotFoundError: No module named 'pandas'\n",
    "Поэтому стоит иметь в виду, что для каждого создаваемого виртуального окружения необходимо отдельно установить все зависимости, которые не входят в стандартную библиотеку Python.\n",
    "Однако это ещё не всё. Когда разработка проекта завершена и мы готовы загрузить его на свой GitHub и поделиться им с коллегами, мы можем сохранить все те версии библиотек, которые использовали при разработке, в файл. Для этого применяется всё та же команда pip freeze, только с указанием имени файла, в который необходимо произвести запись. Традиционно такой файл называют requirements.txt и располагают в корневой директории проекта. Для указания файла используется ключ -r или оператор >:\n",
    "\n",
    "(project_a_venv) $ pip freeze -r requirements.txt\n",
    "или\n",
    "\n",
    "(project_a_venv) $ pip freeze > requirements.txt\n",
    "В результате создаётся текстовый файл requirements.txt, который вы можете поместить в свой репозиторий на GitHub.\n",
    "\n",
    "Когда коллеги будут клонировать ваш проект, им не нужно будет разбираться, какие библиотеки вы использовали в проекте, а тем более — каких версий. Они смогут создать на своём компьютере собственное виртуальное окружение и установить в него все необходимые зависимости, используя лишь одну команду:\n",
    "\n",
    "(имя_виртуального_окружения) $ pip install requirements.txt\n",
    "Удобно, не правда ли?\n",
    "\n",
    "Теперь давайте заглянем «под капот» и поймём, как именно работает изоляция.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "КАК РАБОТАЕТ ИЗОЛЯЦИЯ\n",
    "\n",
    "Чтобы понять, как работает изоляция, давайте проверим, где располагаются исполняемые файлы Python в случае глобального и виртуального окружений.\n",
    "\n",
    "Для начала посмотрим на глобальное окружение. С деактивированной средой запускаем команду:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная команда выводит расположение скрипта, который выполняется при вызове команды python3.\n",
    "\n",
    "Теперь попробуйте запустить ту же самую команду, но уже находясь в одном из виртуальных окружений, например в виртуальном окружении проекта А:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что, активировав среду, мы получаем другой путь к интерпретатору Python. Но как подключение библиотек зависит от расположения интерпретатора? Напрямую.\n",
    "\n",
    "Мы не будем подробно останавливаться на том, как происходит внутреннее управление путями в операционных системах, так как это довольно обширная тема и её изложение будет уникально для каждого типа операционных систем. Если говорить вкратце, при активации виртуального окружения вы меняете специальные переменные среды ОС, в результате чего при запуске команды вызова интерпретатора используете не глобальную версию интерпретатора Python, который имеет доступ ко всем установленным пакетам, а его копию, которая лежит в папке с виртуальным окружением. Этот интерпретатор не имеет доступа к папке, где хранятся библиотеки, установленные в глобальное или любое другое виртуальное окружение — у него она своя. Это же правило работает и в обратную сторону.\n",
    "\n",
    "Примечание. Подробнее о том, как меняются переменные среды, можно узнать в этой статье."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ПРИЧИНЫ ИСПОЛЬЗОВАНИЯ ВИРТУАЛЬНЫХ ОКРУЖЕНИЙ\n",
    "\n",
    "У вас мог возникнуть вопрос: зачем это нужно? Зачем так сложно? Раньше мы спокойно работали в глобальном окружении и даже не знали, что оно глобальное, а сейчас для каждого проекта придётся создавать отдельное виртуальное окружение?\n",
    "\n",
    "Если вы хотите стать профессиональными разработчиками, работать в команде и обеспечивать воспроизводимость библиотек с минимальной затратой времени, то да — создавать виртуальные окружения вам придётся чуть ли не в каждом проекте.\n",
    "\n",
    "Представим следующую ситуацию: у вас есть два проекта — проект A и проект B. Они оба имеют зависимость от одной и той же библиотеки. Проблема становится явной, когда мы начинаем запрашивать разные версии этой библиотеки. Например, может случиться так, что проект A запрашивает версию 1.0.0, а проект B — версию 2.0.0, причём версия 2.0.0 настолько сильно отличается от 1.0.0, что для адаптации проекта А под новую версию придётся его полностью переписывать. Это большая проблема для Python, ведь работая только в глобальном окружении, мы не можем использовать обе версии библиотеки. Так или иначе, возникнет конфликт, который могут решить виртуальные окружения.\n",
    "\n",
    "Вторая причина использования виртуальных окружений — удобная коммуникация внутри команды. Разрабатывая проект в виртуальном окружении, мы можем сохранить только те зависимости и их версии, которые использовали в проекте, например в файл requirements.txt.\n",
    "\n",
    "Затем мы можем передать разработку своим коллегами (например, через GitHub), и они смогут установить только те зависимости, которые необходимы для работы нашего кода.\n",
    "\n",
    "Примечание. Важно отметить, что папку самого виртуального окружения в GitHub помещать не нужно. Всегда добавляйте эту папку в файл .gitignore.\n",
    "\n",
    "Например, мы можем прописать в файле .gitignore строку *venv/, которая будет означать, что всё содержимое папок, названия которых оканчиваются на venv, будет игнорироваться при коммитах:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВИРТУАЛЬНОЕ ОКРУЖЕНИЕ ДЛЯ FLASK-ПРИЛОЖЕНИЯ\n",
    "\n",
    "Пришло время создать виртуальное окружения для нашего веб-сервиса.\n",
    "\n",
    "Предварительно перейдите в каталог, где расположен код вашего проекта из предыдущего модуля.\n",
    "\n",
    "В корневой директории проекта (у нас она называется web) создадим виртуальное окружение с именем project_venv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python3 -m venv project_venv\n",
    "Локальные копии Python и pip будут установлены в каталог project_venv в каталоге вашего проекта.\n",
    "\n",
    "Активируем виртуальное окружение:\n",
    "\n",
    "UNIXWINDOWS\n",
    "$ source project_venv/bin/activate\n",
    "Теперь мы можем переходить к установке пакетов в наше окружение. Сначала установим wheel с локальным экземпляром pip, чтобы убедиться, что наши пакеты будут устанавливаться даже при отсутствии архивов wheel:\n",
    "\n",
    "(project_venv) $ pip install wheel\n",
    "Затем установим Flask, requests и scikit-learn. Чтобы установить несколько пакетов сразу, можно просто перечислить их через пробел после команды install.\n",
    "\n",
    "(project_venv) $ pip install flask requests scikit-learn\n",
    "Затем запустим наш сервер:\n",
    "\n",
    "UNIXWINDOWS\n",
    "(project_venv) $ python3 ./server.py\n",
    "Давайте проверим, что мы установили все необходимые для работы веб-сервиса и его тестирования зависимости. Через браузерную строку зайдите по адресу http://localhost:5000 или http://127.0.0.1:5000. Там должно быть выведено сообщение, что ваш сервер запущен.\n",
    "\n",
    "Также попробуйте отправить POST-запрос на ваш сервер, выполнив клиентский скрипт в соседнем терминале.\n",
    "\n",
    "UNIXWINDOWS\n",
    "(project_venv) $ python3 ./client.py\n",
    "В результате работы скрипта должно быть выведено сообщение о статусе обработки запроса (он должен быть равен 200) и предсказание модели для отправленных данных.\n",
    "\n",
    "Если всё работает корректно, GET- и POST-запросы отработали без ошибок, то мы можем зафиксировать версии наших зависимостей и поместить их в файл requirements.txt в корневой директории проекта:\n",
    "\n",
    "(project_venv) $ pip freeze > requirements.txt\n",
    "В нашей директории появится файл requirements.txt — он ещё пригодится в следующих юнитах.\n",
    "\n",
    "Теперь, если мы загрузим наш код на GitHub (предварительно добавив папку project_venv в файл .gitignore), нашему коллеге Василию необходимо будет склонировать себе репозиторий, а после этого создать виртуальное окружение и активировать его. Чтобы в точности воссоздать все версии зависимостей, которые мы использовали, Василию будет достаточно набрать в терминале следующую команду:\n",
    "\n",
    "$ pip install requirements.txt\n",
    "После этого зависимости внутри виртуального окружения, созданного Василием, будут совпадать с нашими.\n",
    "\n",
    "Virtualenv — полезный инструмент. Однако не всё так гладко, ведь он работает только с Python и не обеспечивает полную изоляцию. Также он не позволяет ограничивать ресурсы для каждого сервиса: например, иногда бывает необходимо разрешить одному сервису использование всех ядер процессора и ограничить — другому. Если мы также хотим автоматически балансировать нагрузку между сервисами, то и тут virtualenv нам не помощник.\n",
    "\n",
    "На эту тему есть прекрасная статья на Хабре.\n",
    "\n",
    "Ещё один недостаток технологии виртуальных окружений состоит в том, что они не помогут, если разработка проекта ведётся на одной операционной системе, а эксплуатация — на другой. В частности, вы могли заметить, что при создании виртуального окружения для нашего веб-сервиса мы ничего не сказали о связке Flask, uWSGI и NGINX — как мы помним по прошлому модулю, эта связка поддерживается только для UNIX-систем. Поэтому нам необходимо создать не просто виртуальное окружение, где мы будет хранить необходимые для работы приложения библиотеки, а что-то вроде карманной операционной системы, внутри которой уже настроено взаимодействие всех необходимых инструментов для работы сервиса, включая установленные внутри версии библиотек. Причём хотелось бы, чтобы эту карманную ОС можно было запускать на любом устройстве, то есть чтобы наш сервис можно было переносить между платформами. Тут к нам на помощь приходят системы контейнеризации, в частности Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Контейнеризация. Docker и Docker Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 2012–2013 гг. появилось несколько систем контейнеризации, которые позволяли иметь дополнительную операционную систему в изолированном от основной ОС виде и не использовали много ресурсов.\n",
    "\n",
    "Контейнеризация — это метод виртуализации, при котором ядро операционной системы поддерживает несколько изолированных экземпляров приложений.\n",
    "\n",
    "Наиболее популярной системой контейнеризации оказался Docker. Сегодня, если кто-то говорит о контейнерах, скорее всего, имеется в виду именно Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути, Docker — это программное обеспеспечение, которое позволяет в автоматическом режиме создавать виртуальные машины и управлять ими. При этом Docker делает это более элегантно по сравнению с обычными средствами виртуализации, например VirtualBox.\n",
    "\n",
    "img\n",
    "Что изображено на схеме выше?\n",
    "Данные схемы демонстрируют отличия с точки зрения архитектуры информационной системы при использовании виртуальных машин и контейнеров. Схемы стоит читать снизу вверх.\n",
    "\n",
    "В случае использования виртуальных машин (Virtual Machines) мы имеем:\n",
    "\n",
    "Инфраструктуру системы (Infrastructure) — рабочие компьютеры пользователей, серверы, облачные технологии и т. д.\n",
    "Операционную систему устройства (Host Operating System) — операционные системы (Windows/Unix/Mac), на которых работают компьютеры;\n",
    "Гипервизор (Hypervisor) — процесс, которые отделяет операционную систему компьютера от физического оборудования. Проще говоря, это специальное приложение, которое позволяет создавать и управлять виртуальными машинами и запускать на одном компьютере множество различных виртуальных операционных систем. Например, для Windows таким приложением является Hyper-V. Подробнее о гипервизорах и их устройствах вы можете прочитать здесь.\n",
    "Гостевые/виртуальные операционные системы (GuestOS) — операционные системы, которые работают внутри виртуальных машин. Их может быть сколько угодно (зависит от возможностей железа, установленного в компьютере, на котором запускаются виртуальные машины).\n",
    "Бинарные файлы и библиотеки (Bins/Libs) — пакеты, которые необходимы для работы приложений, запущенных на каждой из гостевых ОС.\n",
    "Приложения (App) — приложения, которые мы запускаем внутри гостевых ОС. Это может быть несколько серверных приложений, которые ожидают поступающих интернет-запросов, при этом каждое из них запущено под определённой ОС.\n",
    "В случае использования контейнеров (Containers) мы имеем:\n",
    "\n",
    "Инфраструктуру системы (Infrastructure).\n",
    "Операционную систему устройства (Operating System).\n",
    "Движок Докер (Docker Engine) — специальное программное обеспечение для автоматизации развёртывания и управления приложениями в средах с поддержкой контейнеризации. Проще говоря, это контейнеризатор приложений. Он позволяет «упаковать» приложение со всем его окружением и зависимостями в контейнер, который может быть развёрнут на любой операционной системе. В каждом контейнере запущены свои приложения (как правило, один контейнер — одно приложение) со своими зависимостями.\n",
    "Бинарные файлы и библиотеки (Bins/Libs).\n",
    "Приложения (App).\n",
    "Таким образом, из схемы видно, что, в отличие от виртуальных машин, контейнерам не нужна установка отдельных гостевых операционных систем с ненужными функциями, такими как графический интерфейс, встроенные в ОС приложения и т. д. В каждом контейнере содержится своя микро-ОС, в которой можно изолированно запускать отдельные приложения.\n",
    "\n",
    "Докер позволяет собрать приложение со всем его окружением и зависимостями в контейнер. В нашем случае приложением может быть модель ML, предсказывающая стоимость авто, его зависимостями — библиотеки sklearn, numpy и pandas, а окружением — ОС, на которой работает приложение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За счёт того что Docker потребляет не очень много ресурсов машины, на которой находится, можно запускать сразу несколько контейнеров даже на среднестатистическом компьютере. Из-за этого стало принято использовать небольшие контейнеры для каждого конкретного сервиса: например, если у нас есть Django-приложение с базой данных, то сам сервер будет находиться в одном контейнере, а база — в другом. Изоляция часто позволяет добиться улучшения производительности и упрощения миграции сервисов.\n",
    "\n",
    "img\n",
    "Источник изображения\n",
    "\n",
    "У Docker неслучайно такая эмблема и название!\n",
    "Проще всего это представить, воспользовавшись метафорой кораблей и контейнеров. Если необходимо перевезти несколько типов грузов (продукты, тяжёлые машины и химикаты), то сделать это на одном корабле можно, только используя контейнеры и таким образом изолируя грузы друг от друга. Когда грузы находятся в контейнерах, уже не очень важно, что внутри — оно может быть погружено на корабль.\n",
    "\n",
    "Таким образом, контейнеризация — это создание некоторого «ящика» для вашего приложения, в который будут сложены ядро, ОС, библиотеки, ПО и само приложение.\n",
    "\n",
    "img\n",
    "Docker работает с функциями системы Linux и её ядрами, поэтому при работе на других ОС он использует небольшую хитрость: каждый раз в систему устанавливается виртуальная машина с Linux, и Docker работает уже в ней, но мы этого даже не замечаем.\n",
    "\n",
    "ПОДВЕДЁМ ПРОМЕЖУТОЧНЫЙ ИТОГ\n",
    "\n",
    "Контейнер Docker, по сути, представляет собой «виртуальную» файловую систему, в которую вы устанавливаете всё необходимое для запуска вашего приложения. Это «всё необходимое» включает в себя даже ядро системы Linux. При запуске такого Docker ваша базовая система поднимает контейнер с этой файловой системой, и получается легковесная виртуальная машина, что-то вроде карманной операционной системы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Образы (images) — это основные строительные блоки, на основании которых создаются контейнеры (а в них впоследствии упаковываются приложения).\n",
    "\n",
    "Образ, по своей сути — это шаблон, своеобразный чертёж или рецепт, в котором содержится образ базовой операционной системы, код приложения и библиотеки.\n",
    "\n",
    "Запуская на его основе контейнер, мы создаём исполняемый экземпляр, который инкапсулирует требуемое программное обеспечение.\n",
    "\n",
    "Ключевую роль в устройстве образа играет идея о слоях.\n",
    "\n",
    "img\n",
    "В основе каждого docker лежит базовый образ с операционной системой. С каждым новым слоем в ОС добавляются другие компоненты. Каждый слой представляет из себя подобие diff файловой системы. Например, вы взяли образ системы Ubuntu и поставили туда Python. В таком случае ваш образ будет состоять из двух слоёв — самой ОС и файлов Python поверх неё.\n",
    "\n",
    "В качестве базового образа для docker можно использовать не только ОС, но и готовые образы с нужными вам компонентами. Кто угодно может добавлять свои образы в общий регистр, поэтому в нём очень много готовых образов, доступных для расширения. Таким образом, можно взять готовый образ из публичного репозитория в качестве базового и добавлять в него дополнительные слои. Это делается в соответствии с инструкциями из Dockerfile, которые мы подробно рассмотрим дальше.\n",
    "\n",
    "Готовые образы хранятся в Docker Registry. Они могут быть публичными или приватными: например, официальное публичное хранилище — это Docker Hub. Это аналог GitHub, но если последний используется для хранения кода и работы с Git, то Docker Hub используется для хранения docker-образов и работы с Docker.\n",
    "\n",
    "В качестве базового можно использовать абсолютно любой образ. Однако стоит помнить о безопасности и удостовериться, что образ не навредит.\n",
    "\n",
    "img\n",
    "Источник изображения\n",
    "Основное преимущество Docker заключается в том, что с помощью Docker Registry мы можем делиться образами, а значит, легко переносить созданные нами приложения.\n",
    "\n",
    "Для работы с Docker Registry достаточно знать две команды (они очень похожи на команды Git) — подробнее о них мы поговорим далее:\n",
    "\n",
    "docker push — отправить собранный образ в Docker Registry.\n",
    "docker pull — скачать готовый образ из Docker Registry.\n",
    "Существует множество официальных образов. Например, можно найти образ, где в качестве ОС используется Ubuntu, или, например, Linux с уже установленным Python. Есть даже Docker в Docker! Очень удобно, не правда ли?\n",
    "\n",
    "Docker-образ управляется Daemon, который отвечает за все действия, связанные с контейнерами, и, конечно, самим клиентом для взаимодействия с ним.\n",
    "\n",
    "Важно. Зарегистрируйтесь на Docker Hub. Для этого вам понадобится только e-mail. Ваш аккаунт пригодится вам далее при выполнении заданий, а также при работе с самим Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "УСТАНОВКА DOCKER\n",
    "\n",
    "Существует две версии Docker: Docker Community Edition (CE) и Docker Business. Версия Community содержит бесплатный набор продуктов Docker. Корпоративная (Business) версия является сертифицированной и представляет собой контейнерную платформу, предоставляюшую своим пользователям дополнительные платные функции, например управление образами, безопасность образов, оркестрирование и управление средой выполнения контейнеров.\n",
    "\n",
    "Для наших базовых целей будет достаточно и Community-версии, но имейте в виду, что большие компании, для которых важны безопасность и сертификация, а также гибкость работы с внутренней частью контейнеров, как правило, работают в Business-версии.\n",
    "\n",
    "Исконно Docker предназначался только для операционных систем Linux. Контейнеры Docker, созданные в конкретной операционной системе, используют ядро ОС. Иначе говоря, это означает, что мы не можем использовать ядро Windows для запуска контейнеров Linux или наоборот.\n",
    "\n",
    "Однако для систем Windows и MacOS есть обходной путь — приложение Docker Desktop. Поэтому, прежде чем начинать работу с Docker, пользователям этих ОС необходимо установить это приложение.\n",
    "\n",
    "Docker Desktop — это декстопное приложение от разработчиков Docker, первоначально предназначенное для пользователей Windows и MacOS. С помощью графического интерфейса этого приложения можно создавать, тестировать и публиковать свои приложения, предварительно завёрнутые в Docker-контейнеры.\n",
    "\n",
    "img\n",
    "\n",
    "Также вместе с Docker Desktop поставляются сервисы, которые понадобятся нам в дальнейшем, в частности:\n",
    "\n",
    "Движок Docker (Docker Engine) — включает в себя инструменты для построения контейнеров, реестр контейнеров, инструменты оркестрации, среду выполнения и многое другое.\n",
    "Docker Compose — инструмент, который предназначен для организации взаимодействия нескольких контейнеров Docker. Мы поговорим о нём в следующем модуле.\n",
    "Ещё несколько компонентов, которые для нас сейчас не очень важны, но при желании вы можете подробнее узнать о них здесь.\n",
    "Хитрость Docker Desktop заключается в том, что для своих контейнеров он запускает Docker на виртуальной машине под операционной системой Linux. То есть, по сути, при сборке контейнеров вы будете использовать ядро ОС Linux, но даже не заметите этого. Благодаря этой особенности ваши контейнеры можно будет запускать на других компьютерах с ОС Linux или ОС, где установлен Docker Desktop.\n",
    "\n",
    "Мы будем учиться работать с контейнерами, используя инструменты командной строки (терминала) и не прибегая к графическому интерфейсу Docker Desktop. Однако если вы изучите основные концепции работы с консольным Docker, для вас не составит труда разобраться и в графическом интерфейсе этого приложения.\n",
    "\n",
    "Итак, давайте перейдём к установке. Все её шаги уже описаны в инструкциях с официального сайта — мы лишь приведём их здесь и обратим ваше внимание на некоторые нюансы.\n",
    "\n",
    "Примечание. Если вы являетесь пользователем Windows, но работаете с дистрибутивами Linux через WSL, то для вас актуальна установка Docker Desktop для Windows с последующей интеграцией Docker в дистрибутив Linux через WSL. Более подробную информацию о работе с Docker через Windows WSL вы можете найти здесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Создание docker-образов. Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Нам уже пора учиться создавать собственные образы, запускать контейнеры и управлять ими. В этом юните мы рассмотрим основной синтаксис работы с Docker на примере приложения для визуализации данных, а уже в следующем юните применим технологию контейнеров для нашего веб-сервиса и заставим его работать на любой машине.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dockerfile — это специальный файл, в котором содержатся инструкции по сборке контейнера (а точнее, его слоёв): какой тип контейнера и операционную систему использовать, какие дополнительные пакеты установить, какие команды запустить.\n",
    "\n",
    "Так, например, если нам нужен образ для решения задач машинного обучения, то в Dockerfile мы пропишем инструкцию включить в образ библиотеки sklearn или tensorflow.\n",
    "\n",
    "Каждая такая команда приводит к созданию отдельного слоя: diff слоя при добавлении файлов будет состоять из файлов, при выполнении команды — из разницы в файловой системе до выполнения и после.\n",
    "\n",
    "Типичный Dockerfile выглядит примерно так:\n",
    "\n",
    "img\n",
    "Давайте на практике разберёмся, что всё это значит, и соберём свой образ контейнера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внимание! В видео эксперт работает в IDE PyCharm. Вы можете работать в той IDE, к которой привыкли.\n",
    "\n",
    "Примечание. В видео для построения графиков плотности в файле plot.py эксперт применяет функцию distplot() из библиотеки Seaborn. Эта функция будет удалена в версии 0.14.0, и её не рекомендуется использовать. По этой причине в коде, приведённом в тексте модуля, мы заменили функцию distplot() на функцию histplot() для построения гистограмм с параметром kde=True (отображение плотности вероятности).\n",
    "\n",
    "Также мы обновили версии библиотек до более актуальных (подробнее об этом — ниже, в разделе «Добавляем библиотеки в контейнер»).\n",
    "\n",
    "Кроме того, в целях сохранения дальнейшей воспроизводимости мы изменили базовый образ на python:3.9 (в видео эксперт использует python:latest).\n",
    "Мы хотим написать сервис, который создаёт две случайные подвыборки данных из нормальных распределений: первая выборка — с параметрами  и  (параметры стандартного нормального распределения), вторая — с параметрами, которые ввёл пользователь.\n",
    "\n",
    "Для каждой выборки должны строиться и сохраняться в файл plot.png графики плотности распределений. Все файлы с графиками будем помещать в папку output.\n",
    "\n",
    "Мы хотим запускать это приложение в контейнере и обеспечивать его работу на любом компьютере.\n",
    "\n",
    "После окончания работы наш проект будет содержать:\n",
    "\n",
    "само приложение plot.py;\n",
    "папку output, в которой будут храниться результаты работы;\n",
    "приложения, то есть графики плотности распределений в формате PNG;\n",
    "Dockerfile — описание контейнера, чтобы обеспечить работу приложения на любом компьютере;\n",
    "файл requirements.txt — зависимости приложения (библиотеки, которые мы используем).\n",
    "Примечание. Для простоты изложения в данном проекте не используется виртуальное окружение, но мы уверены, что вы самостоятельно можете его создать и установить в него все необходимые зависимости (numpy, matplotlib, seaborn).\n",
    "\n",
    "ШАГ 1. ПИШЕМ ПРИЛОЖЕНИЕ\n",
    "\n",
    "Начнём с написания самого приложения. Пусть сначала исходный код в файле plot.py и папка output будут находиться в корневой директории my_first_container:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ШАГ 2. СОЗДАЁМ DOCKER-ОБРАЗ\n",
    "\n",
    "Наше мини-приложение работает. Теперь мы можем завернуть его в контейнер, поэтому следующим шагом будет создание образа контейнера. Для этого создайте (если вы этого ещё не сделали) файл Dockerfile (без расширения) в корне папки, в которой лежит ваше приложение.\n",
    "\n",
    "Традиционно код самого приложения помещают в папку src (от англ. source — источник), а Dockerfile и файл с зависимостями requirements.txt (о последнем мы поговорим далее) располагают рядом с этой папкой в корневой директории проекта. Тогда директория нашего проекта будет выглядеть следующим образом:\n",
    "\n",
    "my_first_container\n",
    "      ├─src\n",
    "          └─output\n",
    "          └─plot.py\n",
    "      └─Dockerfile\n",
    "Откройте Dockerfile в любом текстовом редакторе или в привычной IDE.\n",
    "\n",
    "Переходим к описанию нашего контейнера. Первое, что нужно обязательно указать в нашем новом Dockerfile, — какой образ мы берём за основу. Базовый образ будет задавать файловую систему контейнера и многие другие его составные конфигурации.\n",
    "\n",
    "Давайте загрузим в качестве основы образ Linux с уже установленным Python. Для указания базового образа, на основе которого будет собираться контейнер, используется ключевое слово FROM. Итак, вот первая строка нашего Dockerfile:\n",
    "\n",
    "FROM python:3.9\n",
    "Примечание. Здесь :3.9 в названии базового образа указывает на его версию. В данном случае мы используем версию 3.9 — с ней в нашем коде не возникнет предупреждений. Но вы можете использовать другие версии: например, python:latest означает использование последней доступной версии.\n",
    "\n",
    "Примечание. В описании образа можно ознакомиться с информацией о том, какие бывают сборки и версии. Например, существуют обычная сборка python:<version> и сборка python:<version>-alpine, созданная на базе Alpine Linux. Последняя весит намного меньше, чем большинство базовых образов дистрибутива (~ 5 МБ). Кроме того, есть сборка python:<version>-slim, которая содержит только минимальные пакеты, необходимые для запуска Python, и не включает в себя стандартные пакеты.\n",
    "\n",
    "Теперь укажем путь к рабочей папке нашего приложения внутри docker-контейнера (вместо /usr/src/app вы можете прописать любой путь, по которому хотите поместить файлы внутри контейнера). Для этого используется ключевое слово WORKDIR.\n",
    "\n",
    "WORKDIR /usr/src/app\n",
    "Примечание. Важно понимать, что файловая система контейнера существует отдельно от вашей. Так как образ python, который мы используем в качестве базового, собран на основе Linux, то и файловая система контейнера будет, как в ОС Linux. Ключевое слово WORKDIR говорит контейнеру, какой каталог будет использоваться при его запуске. В данном случае мы говорим, что та директория, с которой по умолчанию будет запускаться контейнер, — это /usr/src/app.\n",
    "\n",
    "Далее скопируем в рабочую директорию файлы из корня нашего приложения. Для этого используется ключевое слово COPY. В качестве первого аргумента этой директивы указываются папки или файлы, которые мы хотим скопировать с локальной машины, в качестве второго аргумента — куда мы хотим поместить эти копии в контейнере.\n",
    "\n",
    "COPY ./src/ ./\n",
    "Что здесь происходит? Мы указываем, чтобы при создании образа содержимое папки ./src/, в которой находится исходный код нашего приложения, было перемещено в рабочую папку (корневой каталог ./) . В результате при сборке образа контейнера в рабочей директории образа появятся файл plot.py и папка output.\n",
    "\n",
    "img\n",
    "Наконец, напишем команду для запуска скрипта, который будет выполняться вместе с запуском контейнера. Для этого используется директива CMD (от англ. command — команда):\n",
    "\n",
    "CMD [ \"python\", \"./plot.py\" ]\n",
    "Таким образом, промежуточный Dockerfile будет выглядеть так:\n",
    "\n",
    "Файл Dockerfile\n",
    "\n",
    "FROM python:3.9\n",
    "WORKDIR /usr/src/app\n",
    "COPY ./src/ .\n",
    "CMD [ \"python\", \"./plot.py\" ]\n",
    "Теперь откроем терминал, перейдём в папку с нашим приложением и запустим команду для сборки контейнера (docker build):\n",
    "\n",
    "$ docker build -t my_first_image .\n",
    "Разберём команду на составляющие:\n",
    "\n",
    "build сообщает docker, что мы хотим создать образ;\n",
    "ключ -t указывает на название образа;\n",
    ". в конце означает, что Dockerfile нужно искать именно в корне. Так как мы запускаем команду из директории my_first_containter/, а в ней находится Dockerfile, то Docker автоматически найдёт его. Если ваш Dockerfile находится в директории, отличной от той, в которой вы запускаете команду docker build, то вместо \".\" вам необходимо будет указать путь до него.\n",
    "Запускаем команду и видим, что образ успешно создан. В справочной информации отражены все наши сборки. Если на каком-то этапе произойдёт ошибка при сборке, docker уведомит вас об этом в терминале.\n",
    "\n",
    "img\n",
    "Чтобы убедиться, что образ собран, а также посмотреть список доступных образов, можно использовать команду:\n",
    "\n",
    "$ docker images\n",
    "Если вы ранее не работали с Docker, скорее всего, сейчас вы получите следующие образы: my_first_image, python (он использовался в качестве базового для my_first_image) и hello-world (мы запускали его на этапе установки Docker).\n",
    "\n",
    "Команда docker images выводит список собранных образов в виде таблицы со следующими столбцами: REPOSITORY (имя образа), TAG (тег образа, в котором обычно указывается его версия), IMAGE ID (идентификатор образа, по которому его можно однозначно найти, — у вас он может отличаться), CREATED (как давно образ был собран), SIZE (размер образа)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После выполнения команды docker images мы увидим на экране примерно следующую таблицу:\n",
    "\n",
    "img\n",
    "\n",
    "Из неё видно, что образу my_first_image соответствует тег latest.\n",
    "\n",
    "Примечание. Так как образы занимают место в памяти компьютера, неактуальные образы можно удалять с помощью команды docker rmi (от англ. remove image):\n",
    "\n",
    "$ docker rmi <image_id>\n",
    "где image_id — идентификатор образа (столбец IMAGE_ID).\n",
    "\n",
    "ШАГ 3. ЗАПУСКАЕМ DOCKER-КОНТЕЙНЕР\n",
    "\n",
    "Попробуем запустить контейнер на основе нашего образа — для этого используется команда docker run <имя образа>:\n",
    "\n",
    "$ docker run -it --rm --name=my_first_container my_first_image\n",
    "Расшифруем ключи и аргументы этой команды:\n",
    "\n",
    "-it объединяет команды: -i оставляет строку для ввода, а -t выделяет терминал;\n",
    "параметр --rm автоматически удаляет контейнер после завершения его работы (в том числе при завершении с ошибкой) — это позволяет не хранить неактивные контейнеры;\n",
    "параметр --name назначает docker-контейнеру имя (мы задали имя my_first_container).\n",
    "Но вот незадача — после запуска мы увидим ошибку Python:\n",
    "\n",
    "Traceback (most recent call last):\n",
    "  File \"./plot.py\", line 4, in <module>\n",
    "    import seaborn as sns\n",
    "ModuleNotFoundError: No module named 'seaborn'\n",
    "Эта ошибка говорит нам, что какие-то библиотеки не установлены. Почему это произошло? Ответ — в самом определении Docker: это инструмент виртуализации. То есть окружение Docker полностью изолировано от нашей операционной системы. Более того, внутри нашего образа и вовсе используется другая операционная система, а это значит, что внутри контейнера нет тех библиотек, которые есть на нашем компьютере.\n",
    "\n",
    "В таком случае давайте добавим нужные зависимости в Dockerfile.\n",
    "\n",
    "ШАГ 4. ДОБАВЛЯЕМ БИБЛИОТЕКИ В КОНТЕЙНЕР\n",
    "\n",
    "Для этого создадим файл requirements.txt рядом с Dockerfile. Укажем в нём необходимые библиотеки и их версии:\n",
    "\n",
    "my_first_container\n",
    "      ├─src\n",
    "          └─output\n",
    "          └─plot.py\n",
    "      └─Dockerfile\n",
    "      └─requirements.txt\n",
    "Файл requirements.txt\n",
    "\n",
    "numpy == 1.23.4;\n",
    "matplotlib == 3.6.0;\n",
    "seaborn == 0.11.2.\n",
    "Теперь необходимо переместить файл с зависимостями в наш контейнер, а после запустить команду для установки зависимостей.\n",
    "\n",
    "Для этого напишем перед командой CMD, запускающей выполнение скрипта в Dockerfile, строки:\n",
    "\n",
    "COPY ./requirements.txt ./\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "Директива COPY нам уже знакома: она позволяет копировать файлы из локальной директории в файловую систему контейнера.\n",
    "\n",
    "img\n",
    "Директива RUN позволяет запускать любые команды по аналогии с терминалом. Например, поскольку мы работаем на основе базового образа Python, мы можем воспользоваться менеджером пакетов pip для установки зависимостей.\n",
    "\n",
    "Также для команды pip install мы указываем:\n",
    "\n",
    "параметр --no-cache-dir — позволяет не использовать кэш, а скачать пакеты заново. Вы можете не указывать этот параметр, если уверены, что в дальнейшем версии используемых библиотек не изменятся.\n",
    "ключ -r — указывает на файлы с зависимостями.\n",
    "Тогда наш итоговый Dockerfile, на основе которого будет собираться образ контейнера, будет выглядеть следующим образом:\n",
    "\n",
    "Файл ./Dockerfile\n",
    "\n",
    "FROM python:3.9\n",
    "WORKDIR /usr/src/app\n",
    "COPY ./src/ ./\n",
    "COPY ./requirements.txt ./\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "CMD [ \"python\", \"./plot.py\" ]\n",
    "Теперь нам необходимо заново собрать образ (сборка займёт некоторое время):\n",
    "\n",
    "$ docker build -t my_first_image .\n",
    "После этого можно запустить контейнер на основе этого образа:\n",
    "\n",
    "$ docker run -it --rm --name=my_first_container my_first_image\n",
    "Примечание. Для того чтобы посмотреть список запущенных контейнеров, можно воспользоваться командой docker ps. По умолчанию она выводит список активных контейнеров. Для вывода списка всех контейнеров используйте ключ -a, но предварительно перезапустите контейнер без ключа --rm, так как данный ключ удаляет контейнеры.\n",
    "\n",
    "$ docker ps -a\n",
    "Запустите команду в соседнем терминале одновременно с контейнером.\n",
    "\n",
    "Она выводит на экран информацию о контейнерах в виде таблицы со следующими столбцами:\n",
    "\n",
    "CONTAINER ID — идентификатор контейнера;\n",
    "IMAGE — имя образа, на основе которого запущен контейнер;\n",
    "COMMAND — команда, используемая внутри контейнера (то, что мы прописали в директиве CMD в Dockerfile);\n",
    "CREATED — когда был запущен контейнер;\n",
    "STATUS — статус контейнера;\n",
    "PORTS — порты, которые использует контейнер (о них поговорим в следующем юните — сейчас наше приложение не использует веб-интерфейс, и портов у него не будет);\n",
    "NAMES — имя контейнера.\n",
    "Теперь всё работает корректно. После запуска контейнера вас попросят ввести среднее и стандартное отклонение. После исполнения контейнера на экран должна быть выведена фраза \"Файл успешно сохранен\".\n",
    "\n",
    "Однако файл plot.png в папке output не обновился с выполнением скрипта в контейнере. Куда же он тогда «успешно сохранён»?\n",
    "\n",
    "ШАГ 5. СИНХРОНИЗАЦИЯ ПУТЕЙ, ИЛИ КУДА ПРОПАЛ PLOT.PNG\n",
    "\n",
    "Технически файл plot.png удалился вместе с контейнером после того, как запустился и выполнился скрипт plot.py. Docker не сохраняет файлы внутри контейнера, так как внутри контейнера своя отдельная файловая система.\n",
    "\n",
    "Что же делать? Ответ очень прост — нам нужно связать контейнер с локальной файловой системой на нашем компьютере.\n",
    "\n",
    "Для этого укажем параметр --volume или ключ -v в команде docker run.\n",
    "\n",
    "Ключ -v требует указания путей, которые записываются в формате <путь на локальной машине>:<путь в контейнере>:\n",
    "\n",
    "$ docker run -it --rm -v $PWD/src/output/:/usr/src/app/output  --name=my_first_container my_first_image\n",
    "Если всё сделано правильно, после выполнения команды в папке output появится нужный график."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ШАГ 6. ЗАГРУЖАЕМ ОБРАЗ НА DOCKER HUB\n",
    "\n",
    "Большой успех Docker во многом обусловлен возможностью делиться образами контейнеров в Docker Hub.\n",
    "\n",
    "Принцип загрузки образа в Docker Hub очень схож с загрузкой кода на GitHub:\n",
    "\n",
    "создаем локальный образ контейнера;\n",
    "делаем push образа на Docker Hub.\n",
    "Пользователь со своей стороны может:\n",
    "\n",
    "сделать pull нашего образа;\n",
    "запустить образ контейнера на своей локальной машине.\n",
    "Если мы правильно собрали образ контейнера, то благодаря технологии виртуализации пользователю не нужно знать, как устроено наше приложение, на какой операционной системе оно работает, какие зависимости в нём установлены — ему нужно просто запустить наш образ на своей на локальной машине. Это значительно упрощает разработку внутри команды и выведение конечных решений в продакшн.\n",
    "\n",
    "Рассмотрим механизм загрузки образов в Docker Hub по шагам.\n",
    "\n",
    "Первым делом зарегистрируйтесь на Docker Hub, если не сделали этого ранее.\n",
    "Далее необходимо залогиниться под своей учётной записью в самом Docker. Для этого наберите в терминале команду:\n",
    "\n",
    "$ docker login\n",
    "Если вы ранее залогинились в Docker Desktop, данные учётной записи подгрузятся автоматически. Если вы не устанавливали Docker Desktop и не логинились в нём, Docker попросит вас ввести данные учётной записи на Docker Hub.\n",
    "\n",
    "При отправке образа в Docker Hub необходимо указать имя пользователя как часть имени образа, так как Docker Hub организует репозитории по имени пользователя. Любой репозиторий, созданный под учётной записью, включает имя пользователя в имя образа Docker.\n",
    "Поэтому нам необходимо пересобрать наш образ my_first_image, задав ему имя в формате <username>/server_name, где <username> — это ваше имя пользователя в профиле на Docker Hub.\n",
    "\n",
    "$ docker build -t <username>/my_first_image .\n",
    "Далее делаем push нашего образа на Docker Hub. В аргументах команды необходимо указать имя образа, которым мы хотим поделиться:\n",
    "\n",
    "$ docker push <username>/my_first_image\n",
    "Далее откройте ваш профиль на Docker Hub — в нём должен был появиться новый репозиторий с именем <username>/my_first_image:\n",
    "\n",
    "img\n",
    "Вы можете зайти внутрь репозитория и отредактировать его по своему усмотрению. Для этого используется опция Manage Repository:\n",
    "\n",
    "img\n",
    "В открывшемся окне вы увидите страницу своего docker-репозитория. Здесь вновь всё очень похоже на GitHub: есть раздел с кратким описанием образа (Description), а также файл README.md.\n",
    "\n",
    "img\n",
    "Примечание. При желании в файле README.md вы можете на языке MarkDown описать суть образа, а также команды, которые необходимы для его запуска — всё как с GitHub-репозиториями.\n",
    "\n",
    "После того как образ выложен на Docker Hub, любой пользователь может скачать его и воспользоваться им. Для этого используется команда docker pull, в аргументах которой указывается имя репозитория на Docker Hub:\n",
    "\n",
    "$ docker pull <username>/my_first_image\n",
    "После этого образ контейнера станет доступным для запуска (это можно отследить с помощью команды docker images), и его можно запустить стандартной командой run:\n",
    "\n",
    "$ docker run -it --rm -v $PWD/src/output/:/usr/src/app/output  --name=my_first_container my_first_image\n",
    "Обратите внимание: для запуска образов, которые мы получаем через pull, не нужно их собирать, то есть нам не нужен Dockerfile (данный файл по определению предназначен для сборки контейнера). Контейнер уже собран, и нам достаточно запустить его.\n",
    "\n",
    "НА ЭТОМ ВСЁ?\n",
    "\n",
    "Иногда нам может потребоваться задать переменные среды, которые используются для определения констант. Чтобы задать их, в Dockerfile существует инструкция ENV — благодаря ей значение будет доступно в контейнере во время его выполнения.\n",
    "\n",
    "Так в Linux-подобных системах называются переменные, которые определяются на уровне оболочки и используются различными приложениями во время выполнения. Подробнее о них можно узнать в статье.\n",
    "Синтаксис ENV можно найти в официальной документации.\n",
    "\n",
    "В Dockerfile нужно добавить:\n",
    "\n",
    "ENV <key> <value>\n",
    "или\n",
    "\n",
    "ENV <key>=<value> ...\n",
    "Или, к примеру, при запуске контейнера:\n",
    "\n",
    "$ docker run --env <key>=<value>\n",
    "Например, мы хотим, чтобы в нашем контейнере появилась переменная среды NAME, в которой будет указываться имя разработчика контейнера. К этой переменной среды можно будет обратиться из любой части контейнера. Тогда в Dockerfile необходимо добавить объявление такой переменной среды:\n",
    "\n",
    "Файл ./Dockerfile\n",
    "\n",
    "FROM python:3.9\n",
    "ENV NAME=\"Skillfactory\" \n",
    "WORKDIR /usr/src/app\n",
    "COPY ./src/ ./\n",
    "COPY ./requirements.txt ./\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "CMD [ \"python\", \"./plot.py\" ]\n",
    "ПРОМЕЖУТОЧНЫЙ ВЫВОД ПО РАБОТЕ С DOCKER\n",
    "\n",
    "В этом юните мы на примере маленького приложения рассмотрели, как создавать собственные образы, а также основные директивы Dockerfile. Запоминать последние не обязательно — вы всегда можете найти их в документации или в этом гайде. Также мы изучили основные команды, необходимые для работы c Docker.\n",
    "\n",
    "Перечислим их (и пару дополнительных) ещё раз:\n",
    "\n",
    "docker build — создать образ контейнера;\n",
    "docker images — посмотреть список доступных образов;\n",
    "docker rmi — удалить образ;\n",
    "docker run — запустить контейнер;\n",
    "docker stop — остановить контейнер;\n",
    "docker rm — удалить контейнер;\n",
    "docker ps — посмотреть список запущенных контейнеров;\n",
    "docker login - залогиниться в учётной записи Docker Hub;\n",
    "docker push - отправить образ на Docker Hub;\n",
    "docker pull - скачать образ с Docker Hub;\n",
    "docker logs — посмотреть логи;\n",
    "docker kill — экстренно завершить процесс.\n",
    "Полезно! У Docker достаточно богатый CLI (Command-Line Interface), который содержит множество команд, помимо тех, что перечислены в модуле. Больше команд и информации о них вы можете увидеть в официальной документации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Создаём образ веб-сервиса\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте завернём в контейнер веб-сервис для нашего коллеги Василия, а затем загрузим его на Docker Hub, чтобы этот сервис был доступен для использования и Василий смог развернуть его у себя.\n",
    "\n",
    "ШАГ 1. ЗАВОРАЧИВАЕМ FLASK-ПРИЛОЖЕНИЕ В КОНТЕЙНЕР\n",
    "\n",
    "Прежде всего, давайте ещё раз договоримся о расположении файлов в нашей директории. Вынесем файлы с кодом сервера (server.py и папка models) и клиентским приложением (client.py) в папки app и test соответственно. Это нужно для удобства, чтобы не прописывать несколько команд COPY в Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clyent==1.2.1\n",
      "  Downloading clyent-1.2.1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: clyent\n",
      "  Building wheel for clyent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clyent: filename=clyent-1.2.1-py3-none-any.whl size=9177 sha256=1997aa34d8fa91b0f165848d44881caba34c94c9cabc1d86c08e721bf9f1f0e9\n",
      "  Stored in directory: /Users/egor/Library/Caches/pip/wheels/f8/18/64/668f0be15646b951e5f692bdab1c61cab099b486cae1bc09b8\n",
      "Successfully built clyent\n",
      "Installing collected packages: clyent\n",
      "  Attempting uninstall: clyent\n",
      "    Found existing installation: clyent 1.2.2\n",
      "    Uninstalling clyent-1.2.2:\n",
      "      Successfully uninstalled clyent-1.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed clyent-1.2.1\n",
      "Collecting nbformat==5.4.0\n",
      "  Downloading nbformat-5.4.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: traitlets>=5.1 in /Users/egor/anaconda3/lib/python3.11/site-packages (from nbformat==5.4.0) (5.7.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/egor/anaconda3/lib/python3.11/site-packages (from nbformat==5.4.0) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in /Users/egor/anaconda3/lib/python3.11/site-packages (from nbformat==5.4.0) (5.3.0)\n",
      "Requirement already satisfied: fastjsonschema in /Users/egor/anaconda3/lib/python3.11/site-packages (from nbformat==5.4.0) (2.16.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/egor/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat==5.4.0) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/egor/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat==5.4.0) (0.18.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/egor/anaconda3/lib/python3.11/site-packages (from jupyter-core->nbformat==5.4.0) (3.10.0)\n",
      "Installing collected packages: nbformat\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.7.0\n",
      "    Uninstalling nbformat-5.7.0:\n",
      "      Successfully uninstalled nbformat-5.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.29.0 which is incompatible.\n",
      "nbconvert 7.7.3 requires nbformat>=5.7, but you have nbformat 5.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nbformat-5.4.0\n",
      "Collecting requests==2.28.1\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /Users/egor/anaconda3/lib/python3.11/site-packages (from requests==2.28.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/egor/anaconda3/lib/python3.11/site-packages (from requests==2.28.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/egor/anaconda3/lib/python3.11/site-packages (from requests==2.28.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/egor/anaconda3/lib/python3.11/site-packages (from requests==2.28.1) (2023.7.22)\n",
      "Installing collected packages: requests\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.29.0\n",
      "    Uninstalling requests-2.29.0:\n",
      "      Successfully uninstalled requests-2.29.0\n",
      "Successfully installed requests-2.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install clyent==1.2.1\n",
    "!pip install nbformat==5.4.0\n",
    "!pip install requests==2.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
