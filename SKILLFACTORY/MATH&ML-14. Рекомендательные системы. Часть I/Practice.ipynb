{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика\n",
    "✍ В этом модуле мы обсудили, как используются рекомендательные системы, как получают данные для них и как оценивают результаты работы РС. Мы начали знакомиться с алгоритмами построения систем рекомендаций и пока успели изучить более подробно один из них — РС на основе популярности. В этом юните мы построим систему рекомендаций, основываясь именно на этом методе. Вы сможете усовершенствовать её в следующем модуле, после того как освоите другие алгоритмы.\n",
    "\n",
    "Для начала загрузим датасет \"Articles sharing and reading from CI&T DeskDrop\", включающий в себя собранные за один год логи DeskDrop — платформы для внутренних коммуникаций, разработанной CI&T и ориентированной на компании, использующие Google Workspace (Google G Suite). Среди прочего, эта платформа позволяет сотрудникам компаний делиться актуальными статьями со своими коллегами.\n",
    "\n",
    "В датасете содержится около 73 тысяч записей о взаимодействии пользователей с более чем тремя тысячами публичных статей, размещённых на платформе.\n",
    "\n",
    "Информация в наборе данных:\n",
    "Оригинальный URL, название и текст статьи.\n",
    "Контекст посещений пользователей, например дата/время, клиент (мобильное приложение/браузер) и геолокация.\n",
    "Различные типы взаимодействия, что позволяет сделать вывод об уровне заинтересованности пользователя в статьях, например комментарии → лайки → просмотры.\n",
    "Данные включают в себя два файла:\n",
    "\n",
    "shared_articles.csv;\n",
    "users_interactions.csv.\n",
    "Начнём работать с файлом shared_articles.csv. Он содержит информацию о статьях, опубликованных на платформе DeskDrop.\n",
    "\n",
    "Для каждой статьи есть:\n",
    "дата публикации (временная метка),\n",
    "исходный URL-адрес,\n",
    "заголовок,\n",
    "содержание в виде обычного текста,\n",
    "язык статьи (португальский — pt или английский — en),\n",
    "информация о пользователе, который поделился статьёй (автор).\n",
    "Для временной метки существует два возможных типа событий:\n",
    "\n",
    "CONTENT SHARED — статья была опубликована на платформе и доступна для пользователей;\n",
    "CONTENT REMOVED — статья была удалена с платформы и недоступна для дальнейших рекомендаций.\n",
    "Для простоты мы рассматриваем здесь только тип события CONTENT SHARED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_articles = pd.read_csv('/Users/egor/Documents/data_science_course/SKILLFACTORY/MATH&ML-14. Рекомендательные системы. Часть I/data/shared_articles.csv')\n",
    "users_interactions = pd.read_csv('/Users/egor/Documents/data_science_course/SKILLFACTORY/MATH&ML-14. Рекомендательные системы. Часть I/data/users_interactions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6.1\n",
    "\n",
    "Отфильтруйте данные так, чтобы остались только объекты с типом события CONTENT SHARED. Сколько таких объектов в получившейся таблице?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3047"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared = shared_articles[shared_articles['eventType'] == 'CONTENT SHARED']\n",
    "shared.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь откроем второй файл — users_interactions.csv.\n",
    "\n",
    "Давайте предварительно преобразуем столбцы personId, contentId в таблицах к строкам. Это преобразование пригодится нам в дальнейшем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fg/7cyb3m_113j_1hkfwhtbsy8h0000gn/T/ipykernel_10772/778304297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shared.contentId = shared.contentId.astype(str)\n"
     ]
    }
   ],
   "source": [
    "users_interactions.personId = users_interactions.personId.astype(str)\n",
    "users_interactions.contentId = users_interactions.contentId.astype(str)\n",
    "shared.contentId = shared.contentId.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В колонке eventType описаны действия, которые могли совершать пользователи при взаимодействии со статьёй:\n",
    "\n",
    "VIEW — просмотр,\n",
    "LIKE — лайк,\n",
    "COMMENT CREATED — комментарий,\n",
    "FOLLOW — подписка,\n",
    "BOOKMARK — добавление в закладки.\n",
    "В первую очередь нам необходимо понять, как определить, что какая-то статья популярнее других. Если бы из возможных реакций у нас были только лайки или только просмотры, то статьи было бы легко ранжировать в соответствии с этими значениями. Однако у нас есть информация о различных действиях пользователя, и на её основе мы должны создать некий универсальный индекс популярности. Составим его из реакций пользователей, придав им разные веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_interactionsevent_type = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса здесь подобраны исходя из важности каждого действия: оставить комментарий — значит, показать наибольшую вовлечённость, а обычный просмотр, напротив, демонстрирует наименьшую вовлечённость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6.2\n",
    "\n",
    "Создайте признак, который будет отражать числовой вес для взаимодействия со статьёй (в соответствии с приведёнными выше весами). Вычислите среднее значение для полученного признака. Округлите его до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2362885828078327"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_interactions['score'] = users_interactions['eventType'].apply(lambda x: users_interactionsevent_type[x])\n",
    "users_interactions['score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы говорили, что рекомендательные системы подвержены проблеме холодного старта — в таких случаях создавать рекомендации намного сложнее.\n",
    "\n",
    "Задание 6.3\n",
    "\n",
    "Чтобы получить хоть какую-то информацию, на которую можно будет опираться, оставьте только тех пользователей, которые взаимодействовали хотя бы с пятью статьями. Сколько всего таких пользователей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_count = users_interactions.groupby(by='personId')['contentId'].nunique()\n",
    "int_count[int_count > 4].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6.4\n",
    "\n",
    "Теперь оставим только те взаимодействия, которые касаются только отфильтрованных пользователей (то есть тех, которые взаимодействовали как минимум с пятью статьями). Сколько всего таких взаимодействий?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69868"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = users_interactions[\n",
    "    users_interactions['personId'].isin(int_count[int_count > 4].index)\n",
    "    ]\n",
    "interactions.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас каждое отдельное взаимодействие пользователя со статьёй выделено в отдельную запись, то есть пользователь мог просмотреть статью, лайкнуть и прокомментировать её, и всё это отразилось в трёх действиях. Давайте для удобства соединим все эти действия в некоторый коэффициент, который будет отражать интерес пользователя к статье. Так как каждому возможному действию мы ранее уже присвоили вес, то, по сути, нам нужно просто сложить все действия. Однако полученное число будет увеличиваться с количеством действий, и будет очень большой разброс возможных значений. В таких случаях обычно логарифмируют полученный результат с помощью следующей функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6.5\n",
    "\n",
    "Примените упомянутое выше преобразование для логарифмирования к сумме весов для взаимодействия пользователя с каждой конкретной статьёй. Также сохраните для каждой пары «пользователь — статья» значение времени последнего взаимодействия.\n",
    "\n",
    "Найдите среднее по признаку с получившимися временными отсечками. Округлите результат до двух знаков после точки-разделителя.\n",
    "\n",
    "Так как наши данные отсортированы по дате, то для того, чтобы выбрать последнее взаимодействие, необходимо использовать метод max()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_content = interactions.groupby(\n",
    "    by=['personId', 'contentId'], as_index=False\n",
    "    )[['eventType', 'score', 'timestamp']].agg(\n",
    "        {'eventType': 'nunique',\n",
    "        'score': 'sum',\n",
    "        'timestamp': 'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_content['score'] = person_content['score'].apply(lambda x: smooth_user_preference(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470605340.0403006"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_content['timestamp'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>contentId</th>\n",
       "      <th>eventType</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1007001694607905623</td>\n",
       "      <td>-5065077552540450930</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1470395911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1007001694607905623</td>\n",
       "      <td>-6623581327558800021</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1487240080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1007001694607905623</td>\n",
       "      <td>-793729620925729327</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1472834892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1007001694607905623</td>\n",
       "      <td>1469580151036142903</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1487240062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1007001694607905623</td>\n",
       "      <td>7270966256391553686</td>\n",
       "      <td>1</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1485994342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39101</th>\n",
       "      <td>998688566268269815</td>\n",
       "      <td>-401664538366009049</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1474567449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39102</th>\n",
       "      <td>998688566268269815</td>\n",
       "      <td>3456674717452933449</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "      <td>1478802088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39103</th>\n",
       "      <td>998688566268269815</td>\n",
       "      <td>6881796783400625893</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1474567675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39104</th>\n",
       "      <td>998688566268269815</td>\n",
       "      <td>7174452660053929140</td>\n",
       "      <td>1</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>1478812905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39105</th>\n",
       "      <td>998688566268269815</td>\n",
       "      <td>739747367187387064</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1474567514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39106 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   personId             contentId  eventType     score  \\\n",
       "0      -1007001694607905623  -5065077552540450930          1  1.000000   \n",
       "1      -1007001694607905623  -6623581327558800021          1  1.000000   \n",
       "2      -1007001694607905623   -793729620925729327          1  1.000000   \n",
       "3      -1007001694607905623   1469580151036142903          1  1.000000   \n",
       "4      -1007001694607905623   7270966256391553686          1  1.584963   \n",
       "...                     ...                   ...        ...       ...   \n",
       "39101    998688566268269815   -401664538366009049          1  1.000000   \n",
       "39102    998688566268269815   3456674717452933449          1  2.584963   \n",
       "39103    998688566268269815   6881796783400625893          1  1.000000   \n",
       "39104    998688566268269815   7174452660053929140          1  2.321928   \n",
       "39105    998688566268269815    739747367187387064          1  1.000000   \n",
       "\n",
       "        timestamp  \n",
       "0      1470395911  \n",
       "1      1487240080  \n",
       "2      1472834892  \n",
       "3      1487240062  \n",
       "4      1485994342  \n",
       "...           ...  \n",
       "39101  1474567449  \n",
       "39102  1478802088  \n",
       "39103  1474567675  \n",
       "39104  1478812905  \n",
       "39105  1474567514  \n",
       "\n",
       "[39106 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разумеется, для того чтобы впоследствии оценить качество построенной рекомендательной системы, нам нужно разделить выборку на обучающую и тестовую. Так как в реальности рекомендации строятся на основе исторических данных о пользователе и контенте, сделаем в нашей задаче разбиение на обучающую и тестовую выборки по временной отсечке.\n",
    "\n",
    "Задание 6.6\n",
    "\n",
    "Разделите данные на обучающую и тестовую выборки, выбрав в качестве временной отсечки значение 1475519545. Значение отсечки включите в тестовую выборку. Сколько объектов попало в обучающую выборку?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29325"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = person_content[person_content['timestamp'] < 1475519545]\n",
    "test_df = person_content[person_content['timestamp'] >= 1475519545]\n",
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства дальнейшего измерения качества рекомендаций преобразуйте данные так, чтобы получить таблицу в формате, где строка соответствует пользователю, а столбцы будут истинными предпочтениями и рекомендациями в формате списков. На место пустых ячеек поместите пустые списки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_train</th>\n",
       "      <th>true_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1007001694607905623</th>\n",
       "      <td>[-5065077552540450930, -793729620925729327]</td>\n",
       "      <td>[-6623581327558800021, 1469580151036142903, 72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1032019229384696495</th>\n",
       "      <td>[-1006791494035379303, -1039912738963181810, -...</td>\n",
       "      <td>[-1415040208471067980, -2555801390963402198, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-108842214936804958</th>\n",
       "      <td>[-1196068832249300490, -133139342397538859, -1...</td>\n",
       "      <td>[-2780168264183400543, -3060116862184714437, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1130272294246983140</th>\n",
       "      <td>[-1150591229250318592, -1196068832249300490, -...</td>\n",
       "      <td>[-1606980109000976010, -1663441888197894674, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1160159014793528221</th>\n",
       "      <td>[-133139342397538859, -387651900461462767, 377...</td>\n",
       "      <td>[-3462051751080362224]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             true_train  \\\n",
       "personId                                                                  \n",
       "-1007001694607905623        [-5065077552540450930, -793729620925729327]   \n",
       "-1032019229384696495  [-1006791494035379303, -1039912738963181810, -...   \n",
       "-108842214936804958   [-1196068832249300490, -133139342397538859, -1...   \n",
       "-1130272294246983140  [-1150591229250318592, -1196068832249300490, -...   \n",
       "-1160159014793528221  [-133139342397538859, -387651900461462767, 377...   \n",
       "\n",
       "                                                              true_test  \n",
       "personId                                                                 \n",
       "-1007001694607905623  [-6623581327558800021, 1469580151036142903, 72...  \n",
       "-1032019229384696495  [-1415040208471067980, -2555801390963402198, -...  \n",
       "-108842214936804958   [-2780168264183400543, -3060116862184714437, -...  \n",
       "-1130272294246983140  [-1606980109000976010, -1663441888197894674, -...  \n",
       "-1160159014793528221                             [-3462051751080362224]  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "final_df = (\n",
    "    train_df.reset_index()\n",
    "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
    "    .reset_index()\n",
    "    .rename(columns={'contentId': 'true_train'})\n",
    "    .set_index('personId')\n",
    ")\n",
    "\n",
    "final_df['true_test'] = (\n",
    "    test_df.reset_index()\n",
    "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
    ")\n",
    "\n",
    "final_df['true_test'] = [ [] if x is np.NaN else x for x in final_df['true_test'] ]\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6.7\n",
    "\n",
    "Осталось совсем немного — скоро вы получите свою первую систему рекомендаций! Мы будем строить popular-based-модель, а значит, нам необходимо найти самые популярные статьи.\n",
    "\n",
    "Посчитайте популярность каждой статьи как сумму всех логарифмических «оценок» взаимодействий с ней (используя только обучающую выборку). Выберите ID самой популярной статьи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contentId\n",
       "-6783772548752091658    231.177195\n",
       "-133139342397538859     228.024567\n",
       "-8208801367848627943    189.937683\n",
       "8224860111193157980     186.044680\n",
       "7507067965574797372     179.094002\n",
       "-2358756719610361882    175.771101\n",
       "-6843047699859121724    175.108147\n",
       "-1297580205670251233    160.671086\n",
       "8657408509986329668     157.973460\n",
       "3367026768872537336     149.383615\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(by='contentId')['score'].sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо сформировать рекомендации для каждого пользователя. Будем рекомендовать десять самых популярных статей. Также необходимо помнить, что следует предлагать пользователю только то, что он ещё не читал.\n",
    "\n",
    "Задание 6.8\n",
    "\n",
    "Постройте систему рекомендаций. Оцените качество с помощью precision@10 для каждого пользователя (доля угаданных рекомендаций). После этого усредните результат по всем пользователям.\n",
    "\n",
    "Для вычисления precision@10 воспользуйтесь следующей функцией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(column):\n",
    "    return (final_df.apply(lambda row:\n",
    "            len(set(row['true_test']).intersection(set(row[column]))) /\n",
    "            min(len(row['true_test']) + 0.001, 10.0),axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_popular = train_df.groupby(by='contentId')['score'].sum().sort_values(ascending=False)\n",
    "top_popular = top_popular.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "top_k = 10\n",
    "\n",
    "final_df['popular'] = final_df['true_train'].apply(lambda x: top_popular[~np.in1d(top_popular, x)][:top_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006454207722621089"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
